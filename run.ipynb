{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [02:01<00:00, 1401860.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "adaptation() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lavku\\Desktop\\Courses\\EE798L\\few_shot_meta_learning-master\\run.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m adaptation_data \u001b[39m=\u001b[39m data[:config[\u001b[39m'\u001b[39m\u001b[39mnum_ways\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mk_shot\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m adaptation_labels \u001b[39m=\u001b[39m target[:config[\u001b[39m'\u001b[39m\u001b[39mnum_ways\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mk_shot\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m adaptation_loss, _ \u001b[39m=\u001b[39m maml_classifier\u001b[39m.\u001b[39;49madaptation(adaptation_data, adaptation_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Evaluate on a validation set (query set)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m query_data \u001b[39m=\u001b[39m data[config[\u001b[39m'\u001b[39m\u001b[39mnum_ways\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mk_shot\u001b[39m\u001b[39m'\u001b[39m]:]\n",
      "\u001b[1;31mTypeError\u001b[0m: adaptation() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from Maml import Maml\n",
    "\n",
    "# Assuming you have a dataset of images for classification\n",
    "# Here, we'll use the CIFAR-10 dataset as an example\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utils import train_val_split_regression\n",
    "# Configuration for MAML\n",
    "config = {\n",
    "    'num_ways': 10,  # Number of classes\n",
    "    'k_shot': 5,     # Number of support samples per class\n",
    "    # Other necessary hyperparameters...\n",
    "    # You can set up device, learning rates, etc.\n",
    "}\n",
    "\n",
    "config['network_architecture'] = 'CNN'\n",
    "config['batchnorm'] = True\n",
    "config['strided'] = True\n",
    "\n",
    "\n",
    "config['device'] = torch.device('cuda:0' if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "config['loss_function'] = torch.nn.MSELoss()\n",
    "config['train_val_split_function'] = train_val_split_regression\n",
    "config['num_ways'] = 1\n",
    "config['k_shot'] = 5\n",
    "config['v_shot'] = 10\n",
    "config['num_models'] = 16\n",
    "config['KL_weight'] = 1e-5\n",
    "\n",
    "config['inner_lr'] = 0.001\n",
    "config['num_inner_updates'] = 15\n",
    "config['meta_lr'] = 1e-3\n",
    "\n",
    "config['train_flag'] = False\n",
    "config['num_episodes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 73065 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lavku\\Desktop\\Courses\\EE798L\\few_shot_meta_learning-master\\run.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m adaptation_data \u001b[39m=\u001b[39m data[:config[\u001b[39m'\u001b[39m\u001b[39mnum_ways\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mk_shot\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m adaptation_labels \u001b[39m=\u001b[39m target[:config[\u001b[39m'\u001b[39m\u001b[39mnum_ways\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mk_shot\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m maml_classifier\u001b[39m.\u001b[39;49mload_model(resume_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, eps_dataloader\u001b[39m=\u001b[39;49mtrain_loader)  \u001b[39m# Load or initialize the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m adaptation_loss, _ \u001b[39m=\u001b[39m maml_classifier\u001b[39m.\u001b[39madaptation(adaptation_data, adaptation_labels, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lavku/Desktop/Courses/EE798L/few_shot_meta_learning-master/run.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Evaluate on a validation set (query set)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lavku\\Desktop\\Courses\\EE798L\\few_shot_meta_learning-master\\Maml.py:66\u001b[0m, in \u001b[0;36mMaml.load_model\u001b[1;34m(self, resume_epoch, eps_dataloader, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m# ---------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m# run a dummy task to initialize lazy modules defined in base_net\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39m# ---------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m eps_data \u001b[39min\u001b[39;00m eps_dataloader:\n\u001b[0;32m     65\u001b[0m     \u001b[39m# split data into train and validation\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     split_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mtrain_val_split_function\u001b[39;49m\u001b[39m'\u001b[39;49m](eps_data\u001b[39m=\u001b[39;49meps_data, k_shot\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mk_shot\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     67\u001b[0m     \u001b[39m# run to initialize lazy modules\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     base_net\u001b[39m.\u001b[39mforward(split_data[\u001b[39m'\u001b[39m\u001b[39mx_t\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lavku\\Desktop\\Courses\\EE798L\\few_shot_meta_learning-master\\_utils.py:114\u001b[0m, in \u001b[0;36mtrain_val_split_regression\u001b[1;34m(eps_data, k_shot)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39m# due to the usage of data loader, the data is in shape (1, num_samples)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# hence, we need to transpose to get the format of mini-batch of samples\u001b[39;00m\n\u001b[0;32m    112\u001b[0m eps_data_batch \u001b[39m=\u001b[39m [eps_data[i]\u001b[39m.\u001b[39mT \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(eps_data))]\n\u001b[1;32m--> 114\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mx_t\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eps_data_batch[\u001b[39m0\u001b[39;49m][k_ids]\n\u001b[0;32m    115\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39my_t\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eps_data_batch[\u001b[39m1\u001b[39m][k_ids]\n\u001b[0;32m    116\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mx_v\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m eps_data_batch[\u001b[39m0\u001b[39m][v_ids]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 73065 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "# Train and validate the MAML model\n",
    "maml_classifier = Maml(config)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Perform adaptation step on the current task (episode)\n",
    "        # This involves updating the inner loop parameters\n",
    "        adaptation_data = data[:config['num_ways'] * config['k_shot']]\n",
    "        adaptation_labels = target[:config['num_ways'] * config['k_shot']]\n",
    "        model = maml_classifier.load_model(resume_epoch=0, eps_dataloader=train_loader)  # Load or initialize the model\n",
    "        adaptation_loss, _ = maml_classifier.adaptation(adaptation_data, adaptation_labels, model)\n",
    "\n",
    "        # Evaluate on a validation set (query set)\n",
    "        query_data = data[config['num_ways'] * config['k_shot']:]\n",
    "        query_labels = target[config['num_ways'] * config['k_shot']:]\n",
    "        validation_loss, accuracy = maml_classifier.evaluation(query_data, query_labels, model)\n",
    "\n",
    "        # Print losses and accuracy\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Batch [{batch_idx + 1}/{len(train_loader)}] \"\n",
    "              f\"Adaptation Loss: {adaptation_loss.item():.4f}, Validation Loss: {validation_loss:.4f}, \"\n",
    "              f\"Validation Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
